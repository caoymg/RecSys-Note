### *Title: Adversarial Point-of-Interest Recommendation*

###### Authors: Fan Zhou, Ruiyang Yin, Kunpeng Zhang, Goce Trajcevski, Ting Zhong, Jin Wu

###### Publication: [WWW '19: The World Wide Web Conference](https://dl.acm.org/doi/proceedings/10.1145/3308558)May 2019 Pages 3462–34618https://doi.org/10.1145/3308558.3313609

###### Note: Yiming Cao



#### **1. Introduction**

- propose a method – APOIR – to learn underlying user preference distribution.
  - *R* recommends POIs based on the currently learned user preference distribution 
  - *D* judges whether the recommended POIs are true locations visited by that user and provides guidance to improve *R*.
- geographical and social influence are also incorporated into the APOIR to further improve the performance.
- unifies reinforcement learning and matrix factorization methods into an adversarial learning framework for POI recommendation.



#### 2. **Preliminaries**

- Given a set of POIs L (|L| = *M*) and a set of users U (|U | = *N*), each with associations to multiple historical check-ins L*ui*, **POI recommendation** aims at recommending each user *ui* ∈ U with *top-K new* POIs in the set of LH*ui* = L − L*ui* that *ui* is likely to be interested in but has never visited before.
- **Matrix Factorization (MF)**:  decomposes the user check-in matrix C ∈ R*N* ×*M* into a **user matrix** U ∈ R*N* ×*Q* and a **POI matrix** L ∈ R*M*×*Q* with *Q*-dimensional latent factors.



#### 3. Methods

- *Temporal & sequential preference modeling*

  -  a variant of GRU, combined with MF, to capture both temporal and sequential preference of users.

    - time gate *Tt* captures the temporal preference of users, as well as POI representation  *lj* , and is used to control the influence of previous hidden state*ht-1* in Eq.(4). 

    <img src="https://p6-tt-ipv6.byteimg.com/origin/pgc-image/6c1f2decb4fc4a06a79b36549951eb31" width="50%" height="50%" />

    - Finally, a user’s temporal and sequential preferences are coded in the last hidden state *ht* , which is then used to update user representation with an element-wise product as uˆ*i* = u*i* ⊙ *ht* .
    - The new user latent factor representation uˆ*i* would be used in the following adversarial learning.

- *Adversarial Learning*

  - The **recommender *Rθ*** here is a generator analogue in GAN where it mainly fits a true distribution of data *p true* (L|*ui* ). Such a user-POI preference distribution is approximated using the **pairwise bayesian personalized ranking (BPR)**, where **user representation** is obtained via above described temporal GRU. The **objective** is to learn a *Rθ* where the true distribution is close enough to the empirical one so that it is difficult for the discriminator to decide whether the POI is generated by *Rθ* or from the true distribution.

  -  The objective of the **discriminator** is to maximize the probability of correctly distinguishing the true check-in locations from the generated recommended POIs by the recommender, given **positive samples from true preference distribution **and **non-visited samples from the recommender**.

  - POIs *lR* sampled from the recommender *Rθ* is discrete, J*R* (*ui* ) cannot be directly optimized with gradient descent as in

    continuous GANs, use policy gradient based REINFORCE algorithm to derive the gradient.

-  *Modeling Reward*

  - exploit two most important factors , i.e., geographical and social influence, for explicitly measuring reward of candidate POIs. Specifically, we consider following reward *λ* Eq.(9) in Eq.(8):
    -  **Geographical reward R*дeo*** is initialized with 0 in each column. We set the *j* *th* item *l* *j* ∈ R*дeo* as 1 if POI *l* *j* is within a distance *d* to *any* visited POIs for user *u**i* . That is, we are interested in including the nearby POIs N (*l* *j* ) for all check-ins of user *ui* into the candidate list and magnify its importance since people are normally visiting the neighboring POIs.
    -  **Social reward R*soc*** is generated in a similar way by setting the *j* *th* column *uj* ∈ R*soc* to 1 if corresponding POI has been visited by *ui* ’s friend *u**j* ∈ F (*u**i* ), where F (*u**i* ) denotes the friends of *ui-1* motivated by the observation that people may visit the POIs where their friends have visited before.

  <img src="https://p6-tt-ipv6.byteimg.com/origin/pgc-image/0598513b5cbc47bb99bcb6b414cb9480" width="50%" height="50%" />

#### 4. Experiments

<img src="https://p6-tt-ipv6.byteimg.com/origin/pgc-image/f65133217e06467b8ba82da282ada616" width="50%" height="50%" />

- *Evaluation*
  
  - Pre@K (precision), Rec@K(recall), nDCG@K (normalized discounted cumulative gain), and MAP@K (mean average precision)
  
- *Baselines*

  **– USG**: is a collaborative filtering-based recommendation with user preference, social influence and geographical influence

  simultaneously incorporated.

  **– MGMPFM**: combines Poisson factor model and a multi-center Gaussian based geographical modeling method.

  **– LFBCA**: is a link-based method that constructs a graph to model users and their relations.

  **– iGSLR**: exploits personalized geographical preference and social influence with FCF (friend-based CF) and KDE (kernel

  density estimation).

  **– LORE**: considers sequential influence in addition to social and geographical influence by FCF, KDE and MF.

  **– IRenMF**: incorporates characteristics of neighboring POIs in both individual level and region level into weighted matrix

  factorization for POI recommendation.

  **– GeoMF**: integrates spatial influence in user geographical regions and its propagation.

  **– RankGeoFM**: is a ranking based geographical factorization method incorporating the spatial-temporal factors.

  **– GeoTeaser**: a temporal POI embedding model to capture the contextual check-in information and the temporal characteristics using word2vec framework.

  **– PACE**: builds a word2vec-based architecture to jointly learn the embeddings of users and POIs to predict both user preference over POIs and context associated with users and POIs.

<img src="https://p6-tt-ipv6.byteimg.com/origin/pgc-image/fc357c668e1f4e41848953e838b2b925" width="70%" height="70%" />

